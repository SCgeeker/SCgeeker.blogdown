<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects on Sau-Chin Chen&#39;s Website</title>
    <link>http://scchen.com/en/project/</link>
    <description>Recent content in Projects on Sau-Chin Chen&#39;s Website</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 Sau-Chin Chen</copyright>
    <lastBuildDate>Mon, 01 Jan 2018 00:00:00 +0000</lastBuildDate>
    <atom:link href="/en/project/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Orientation Effects</title>
      <link>http://scchen.com/en/project/mental-simulation/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>http://scchen.com/en/project/mental-simulation/</guid>
      <description>&lt;p&gt;When we are reading the sentence describing the object in the context, such as &amp;lsquo;The eagle is in the sky&amp;rsquo;, our minds would catch the visual properties of the eagle. This theory has acquired the evidence of the findings from the sentence-picture verification task. In this verification task the target objects matched the probe sentence (e.g., the flying eagle) are verified faster than the target objects mismatched the probe sentence (e.g., the standing eagle). This findings are called &amp;ldquo;match advantage&amp;rdquo;. So far the target objects matched on shape, color, size, and orientation have shown the relatively roubust results. These respective match advantage are called shape effect, color effect, size effect, and orientation effect.&lt;/p&gt;

&lt;p&gt;Among the visual features, the orientation effect has the inconsistent findings between the studies with the comprehention task (Stanfield &amp;amp; Zwaan, 2001; Zwaan &amp;amp; Pecher, 2012) and the studies without the comprehension task (De Koning, Wassenburg, Bos, &amp;amp; van der Schoot, 2017; Hoeben-Mannaert, Dijkstra, &amp;amp; Zwaan, 2017). Compared to the other three visual features, the match advantage usually shows up regardless of the design of a study. This project aims to find the clue to answer why the inconsistent findings happened to the object orientation.&lt;/p&gt;

&lt;p&gt;The frist working hypothesis is the adjustment of object size. Until present, all the studies of orientation effect used the objects that are able to be manipulated by single hand. During the collaboration with &lt;a href=&#34;https://rolfzwaan.blogspot.tw/&#34; target=&#34;_blank&#34;&gt;Rolf Zwaan&lt;/a&gt; and &lt;em&gt;Bjorn de Korning&lt;/em&gt;, we have developed the hypothesis how the large objects would show the robust orientation effect than the small objects. This hypothesis have been initially confirmed in the mixed-platform study across langages (English, Dutch, and Chinese). After erased the explicit expression about object orientation in the probe sentences, we have preregistered the web-based study for the final confirmation. This study is going to start once we have the acceptence-in-principle from our submitted journal.&lt;/p&gt;

&lt;p&gt;The second working hypothesis came from the moments I was preparing the materials for the first working hypothesis. Since all the past studies were from Americans and Europeans, will the original materials cause the larger effects in the other languages and cultures? More than ten years ago, there is the study suggesting that Arabic speakers are more sensitive to the direction Italians (Maass and Russo, 2003). If the original orientation effect(Stanfield &amp;amp; Zwaan, 2001) could be found in some languages out of North America and European, this hypothesis has the initial empirical evidence. At the date &lt;a href=&#34;https://christopherchartier.com/&#34; target=&#34;_blank&#34;&gt;Christopher Chartier&lt;/a&gt; claimed the establishment of &lt;a href=&#34;https://christopherchartier.com/2017/08/26/building-a-cern-for-psychological-science/&#34; target=&#34;_blank&#34;&gt;Psychological Science Accelerator&lt;/a&gt;, I got this opportunity. In 2018, we will invite the member laboratories join this study.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
