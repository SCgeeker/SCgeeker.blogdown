<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>statistics | Sau-Chin Chen&#39;s website</title>
    <link>http://scchen.com/tag/statistics/</link>
      <atom:link href="http://scchen.com/tag/statistics/index.xml" rel="self" type="application/rss+xml" />
    <description>statistics</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en</language><copyright>© 2017~2021 Sau-Chin Chen</copyright><lastBuildDate>Tue, 14 Aug 2018 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://scchen.com/media/icon_huc82a1284e5a96b215db79368a756ab5f_356981_512x512_fill_lanczos_center_2.png</url>
      <title>statistics</title>
      <link>http://scchen.com/tag/statistics/</link>
    </image>
    
    <item>
      <title>If Emily Rosa met Thomas Bayes ...</title>
      <link>http://scchen.com/post/if-emily-rosa-met-thomas-bayes/</link>
      <pubDate>Tue, 14 Aug 2018 00:00:00 +0000</pubDate>
      <guid>http://scchen.com/post/if-emily-rosa-met-thomas-bayes/</guid>
      <description>&lt;p&gt;Twenty years ago 11-years-old Emily Rosa and her parents publsihed &lt;a href=&#34;https://jamanetwork.com/journals/jama/fullarticle/187390&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;their study&lt;/a&gt; in Journal of the American Medical Association. This study was designed by Emily herself two years before the publication. Before 1998, &lt;a href=&#34;https://en.wikipedia.org/wiki/Therapeutic_touch&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Therapeutic Touch&lt;/a&gt; (commonly shortened to &amp;ldquo;TT&amp;rdquo;) had been advocated in hundreds of hospitals and nursing schools in North America. Forty thousands of health care professionals had been trained to use TT for their patient. The trained TT professionals were claimed, by the promoters, have the skill to manipulate &lt;strong&gt;the energy field surrounded human body&lt;/strong&gt; without touching. TT professionals just stoped the plams above the patients&#39; body for minutes to cure their pain and anxiety. However, the evidence about the reality of TT was vague.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;theraputic-touch.jpg&#34; alt=&#34;A TT therapist is healing a paitent.&#34;&gt;&lt;/p&gt;
&lt;p&gt;Emily was curious how real was TT technique. To test their skill under unbiased observations, she designed the test table like the below figure shows. Every trainee would run 10 trials in one test. In each trial, Emily placed her right hand above one of the participated trainee&#39; hand, decided by flipped coin. She had the hypothesis if the skill of TT trainees was real, they would give the correct answers in at least 8 of the trials.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;joc71352f1.gif&#34; alt=&#34;Emily Rosa is testing her subjest.&#34;&gt;&lt;/p&gt;
&lt;p&gt;Emily ran this study two times between 1996 and 1997. At the first time 15 TT trainees were invited to this study. She deiced to run the second time after the TV station interviewed her. At the second time 13 TT trainees, included 7 had participated in the first time, joined this study.  Their analysis showed the average accuracy of these trainees as equal to the random guessing.&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/mNoRxCRJ-Y0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;We would learn many things from Emily&amp;rsquo;s study till today. First of all the critical finding was the null effect. Today the behavioral scientists share more attention about the null effect than 1998. The other interesting thing is that the prediction could be verified by one point. It is rare to use the one-sample t-test in the psychological studies, but almost every psychologist learned the one-sample t-test before the independent t-test and paired t-test. Latest but may be critical, the idea of little Emily embodied the statistical thinking.&lt;/p&gt;
&lt;p&gt;Emily&amp;rsquo;s data were summarized in the reproduced figure as below. They ran the one-sample t-test for the results of two times respectively. The analyses disconfirmed the reality of TT technique, but Emily and her parents might show a kind of researcher flexibility: they used the small samples in their first and follow-up studies. Could we upgrade their results in addition to conduct a registered replication plan?&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;
&lt;img src=&#34;http://scchen.com/post/if-emily-rosa-met-thomas-bayes/index_files/figure-html/Rosa1998Fig2-1.png&#34; alt=&#34;Reproductive test results of Rosa et al.(1998)&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Figure 1: Reproductive test results of Rosa et al.(1998)&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;If Emily had learned Bayesian statistics in 1998, she would show the reporters her stronger belief how fake the TT technique was. Next, I use the binomial probability distribution to reanalyze Emily&amp;rsquo;s data in the simple Bayesian inference. My first step is the recovery of the original correct frequency of every TT participant. Although Emily&amp;rsquo;s paper gave the range of scores (initial study: 2 to 8; follow-up study: 1 to 7), they did not provide the how many correct trials conducted by every participant. I arranged the numbers based on the averages and number of total correct responses as follows:&lt;/p&gt;
&lt;p&gt;(R-chunk, vectors of numbers)&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Initial test data
Data_initial &amp;lt;- c(2,3,3,3,3,4,5,5,5,5,5,6,6,7,8)
# Follow-up data
Data_followup &amp;lt;- c(1,3,3,3,3,4,4,4,4,5,5,7,7)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then I required the theoretical parameters representing Emily&amp;rsquo;s hypothesis. Her study in nature was a game of coin tossing. She assumed certificated TT participants, given their technique was real, could answer correctly in more than 8 trials. In the other word, among the ten coins flipped by Emily, they could look into which 8, 9, or all sides on the top. Before the initial study, Emily could assume the probability each participant give the correct answer in a trial to be more than 0.5. If she used Bayesian inference, she would expect the posterior probability higher than 0.8. Therefore I prepared the uniform distribution ranged between 0.5 and 1 as the prior probability of the Bayesian inference.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Study parameters
n_TT &amp;lt;- 10000
n_trials &amp;lt;- 10

# Theoretical accuracies
min_acc &amp;lt;- 0.5
max_acc &amp;lt;- 1

### Analaysis of initial test

# Prior accuracy of TT partitioners before initial test
Correct_proportions_initial &amp;lt;- runif(n=n_TT, min=min_acc,max=max_acc)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It was recorded that only one participant returned 8 correct answers in the initial study. My Bayesian model used the binomial distribution with the arguments of 10 trials and prior probabilities. This model generated the posterior probability distribution given the data of Emily&amp;rsquo;s initial study. The average of the initial study was 4.67; thus I retrieved the posterior probability distribution of 5 from the Bayesian model.&lt;/p&gt;
&lt;!---
(R-chunk, Bayesian model and posterior histogram of initial)
---&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;
&lt;img src=&#34;http://scchen.com/post/if-emily-rosa-met-thomas-bayes/index_files/figure-html/Bayes-initial-1.png&#34; alt=&#34;Bayes&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Figure 2: Bayes&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;
&lt;img src=&#34;http://scchen.com/post/if-emily-rosa-met-thomas-bayes/index_files/figure-html/Post-initial-1.png&#34; alt=&#34;Posterior distribution&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Figure 3: Posterior distribution&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;According to the posterior probability distribution of the initial study, the probability of TT trainees returned more than 8 correct answers would be &lt;code&gt;0.018&lt;/code&gt;. Because Emily had never considered the reproduction of her initial study before the interview, the follow-up study was like the second chance for the TT trainees. After the initial study, Emily updated her assumption of how many correct answers TT trainees could return in this study. I used the posterior probability distribution of the initial study as the prior probabilities for the analysis of the follow-up study. Then I built the Bayesian model and retrieved the posterior probability distribution given the average 4.06, I truncated to 4.&lt;/p&gt;
&lt;!---
(R-chunk, Bayesian model and posterior histogram of follow-up)
---&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;http://scchen.com/post/if-emily-rosa-met-thomas-bayes/index_files/figure-html/Bayes-followup-1.png&#34; alt=&#34;Bayesian inferece of follow-up study: Prior probability distribution (y axis) and Conditioning correct frequencies (x axis)&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Figure 4: Bayesian inferece of follow-up study: Prior probability distribution (y axis) and Conditioning correct frequencies (x axis)&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;
&lt;img src=&#34;http://scchen.com/post/if-emily-rosa-met-thomas-bayes/index_files/figure-html/Post-followup-1.png&#34; alt=&#34;Posterior probability distribution of follow-up study result&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Figure 5: Posterior probability distribution of follow-up study result&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The histogram of the posterior probability distribution shows zero possibility beyond 8. My reanalysis indicates that Emily&amp;rsquo;s study indeed falsified the reality of Therapeutic Touch. You may wonder if people have updated the understanding of Therapeutic Touch because of Emily&amp;rsquo;s study. Till today &lt;a href=&#34;http://therapeutictouch.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;the official website of Therapeutic Touch&lt;/a&gt; is regularly upgrading the latest information. More efforts are required to guide people thinking this world with scientific and statistical knowledge.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Display Math Equation in Post</title>
      <link>http://scchen.com/post/2016-04-05-display-math-equation-in-post/</link>
      <pubDate>Tue, 05 Apr 2016 00:00:00 +0000</pubDate>
      <guid>http://scchen.com/post/2016-04-05-display-math-equation-in-post/</guid>
      <description>
&lt;script src=&#34;http://scchen.com/post/2016-04-05-display-math-equation-in-post/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;There will be many posts demostrate how to transfer the mathematical laws to the codes, and the reversed flaw. I start from this famous equation:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ E = mc^2 \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Use the steps 1 and 2 indtroducted in &lt;a href=&#34;http://tinyheero.github.io/2015/12/06/rmd-to-jekyll-protect-eqn.html&#34;&gt;Fong Chun Chan’s post&lt;/a&gt;, my website is able to show the equation in any post. Because this theme use &lt;code&gt;kramdown&lt;/code&gt; as the engine of markdown, I pass the step 4.&lt;/p&gt;
&lt;p&gt;Here are the proof the central limitation theorem. Mix of inline and one-line equations.&lt;br /&gt;
We have a sequence of independent random variables,&lt;span class=&#34;math display&#34;&gt;\[ X_1, X_2, \ldots \]&lt;/span&gt;&lt;br /&gt;
And the mean and variance of them:&lt;br /&gt;
Mean &lt;span class=&#34;math display&#34;&gt;\[ E \left[{X_i}\right] = \mu \in \left({-\infty \,.\,.\, \infty}\right) \]&lt;/span&gt;&lt;br /&gt;
Variance &lt;span class=&#34;math display&#34;&gt;\[ V \left({X_i}\right) = \sigma^2 &amp;gt; 0 \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Assume:&lt;br /&gt;
&lt;span class=&#34;math display&#34;&gt;\[ S_n = \sum_{i \mathop = 1}^n X_i \]&lt;/span&gt;&lt;br /&gt;
Then:&lt;br /&gt;
&lt;span class=&#34;math display&#34;&gt;\[ \displaystyle \frac {S_n - n \mu} {\sqrt {n \sigma^2} } \xrightarrow {D} N \left({0, 1}\right)\]&lt;/span&gt; as &lt;span class=&#34;math display&#34;&gt;\[ n \to \infty \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Embedded tex codes in &lt;code&gt;$$ ... $$&lt;/code&gt;, the equation was transfered inline or in single line. Thus I pass the step 3 of &lt;a href=&#34;http://tinyheero.github.io/2015/12/06/rmd-to-jekyll-protect-eqn.html&#34;&gt;Fong Chun Chan’s method&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note.&lt;/strong&gt; Justify the last equation in 2021-05-13 20:51:38&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Learning Sampling Distribution in R Programming</title>
      <link>http://scchen.com/post/learning-sampling-distribution-in-r-programming/</link>
      <pubDate>Wed, 30 Mar 2016 00:00:00 +0000</pubDate>
      <guid>http://scchen.com/post/learning-sampling-distribution-in-r-programming/</guid>
      <description>&lt;p&gt;Sampling distribution is the set of possible outcomes when we collect data through the randomization procedure (random sampling, ramond assignment). Do a simulation work is the best way to understand the sampling distribution. A simulation work is unrelated to any context we collect the data. You can connect the simulation work to any randominzation in the real world.&lt;/p&gt;
&lt;p&gt;In this pseudo experiment, there are only ten observations we will collect in every sample. They are 1, 2, 3, 4, 5, 6, 7, 8, 9, 10. Accodring to the design of the experiment, a sample will have one observation to countless observations. I assume the distrubtions are accumulated from 100 samples of 1 observation, 9 observations, ,16 observations, 25 observations, and 36 observations. Every sample will be collapsed to a average value and become the components of sampling distribution. I use &lt;code&gt;ggplot2&lt;/code&gt; to draw the five sampling distributions. Look at what they are look like.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;suppressPackageStartupMessages({
  library(ggplot2)
  library(xtable)
  })

set.seed(1)
OBV &amp;lt;- 1:10
Dist1 &amp;lt;- NULL
Dist9 &amp;lt;- NULL
Dist16 &amp;lt;- NULL
Dist25 &amp;lt;- NULL
Dist36 &amp;lt;- NULL
count = 100
while(count &amp;gt; 0){Dist1 &amp;lt;- c(Dist1,sample(OBV, 1, replace = TRUE)); count &amp;lt;- count - 1}
count = 100
while(count &amp;gt; 0){Dist9 &amp;lt;- c(Dist9,mean(sample(OBV, 9,replace = TRUE) ) ); count &amp;lt;- count - 1}
count = 100
while(count &amp;gt; 0){Dist16 &amp;lt;- c(Dist16,mean(sample(OBV, 16,replace = TRUE) ) ); count &amp;lt;- count - 1}
count = 100
while(count &amp;gt; 0){Dist25 &amp;lt;- c(Dist25,mean(sample(OBV, 25,replace = TRUE) ) ); count &amp;lt;- count - 1}
count = 100
while(count &amp;gt; 0){Dist36 &amp;lt;- c(Dist36,mean(sample(OBV, 36,replace = TRUE) ) ); count &amp;lt;- count - 1}
Dist.df &amp;lt;- data.frame(Size = factor(rep(c(1,9,16,25,36), each=100)), Sample_Means = c(Dist1, Dist9, Dist16, Dist25, Dist36) )
ggplot(Dist.df, aes(Sample_Means, fill = Size)) + geom_histogram() + facet_grid(. ~ Size)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://scchen.com/post/learning-sampling-distribution-in-r-programming/index_files/figure-html/Sampling-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We call the set of observations 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 &lt;strong&gt;population&lt;/strong&gt; in any circumstance we conduct this experiment. This population has the average 5.5 and the variance/standard deviation 8.25/2.87. With the increase of sample size, you find more and more samples collapsed to the average of population. The variation of each sample distribution decreases with the increasing of sample size as well. The following table illustrate the average and variance/standard deviation of each sampling distribution.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Sample Size&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Average&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Variance&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Standard Deviation&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;6.06&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;8.14&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;2.85&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;9&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;5.62&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.91&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.96&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;16&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;5.6&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.58&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.76&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;25&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;5.54&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.43&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.66&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;36&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;5.51&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.27&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.52&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;There are three findings in this simulation. First, the average of every sample is as equal as the average of population. Second, the variance of every sample is close to the divide of population variance by the sample size. Third, the standard deviation of every sample is close to the divide of population standard deviation by the square of sample size. These facts matches &lt;a href=&#34;https://en.wikipedia.org/wiki/Central_limit_theorem&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Central limit theorem&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
