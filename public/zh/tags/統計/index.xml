<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>統計 on 暗微幽光</title>
    <link>/zh/tags/%E7%B5%B1%E8%A8%88/</link>
    <description>Recent content in 統計 on 暗微幽光</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-tw</language>
    <copyright>&amp;copy; 2017 Sau-Chin Chen</copyright>
    <lastBuildDate>Thu, 21 Sep 2017 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/zh/tags/%E7%B5%B1%E8%A8%88/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>更嚴苛的標準能否打造嚴謹的科學？</title>
      <link>/zh/post/text_2017010/</link>
      <pubDate>Thu, 21 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/zh/post/text_2017010/</guid>
      <description>為何要重新定義統計顯著水準？就在今年七月下旬，來自重要的社會科學領域：有心理學、社會學、經濟學、政治學等，著作等身的72名資深學者。合作撰寫論文“Redefine statistical significance”，倡議從今天起，所有科學研究的統計顯著水準標準，從.005開始起算。經過一個多月的熱議，這篇論文已於九月一日被Nature Human Research正式接受。
這篇論文現世之前，使用統計檢定分析資料的研究者，在各自的專業領域內依靠有共識的水準，判斷結果是否符合預期或假設。像是心理學、教育界、以及許多醫療研究，採取多數學過統計者熟知的.05。公認是硬科學的高能物理研究，採用5個標準差之外的.000006做為顯著水準。雖然.005與.000006依然有不小的差距，比一般接受的.05是嚴苛十倍的標準。此倡議一出，立刻有新進學者表達，採此標準，會增加研究所的樣本(估計增加70%才能達到.005)，且不利新想法被人看見的意見。
提出這項倡議的主要目的是改善社會科學領域，充斥高比例偽陽性結果(false-positive results)的新奇研究現象。這類研究的特徵是研究想法有創意，設計符合最起碼的科學標準，但是分析結果只是剛好小於.05，而且尚未有可信的重現研究結果。這種研究非常有可能無法被重現，例如兩個月前我注意到的這一篇。Benjamin等72位學者倡議改成.005的重要理由，是如此能明顯降低偽陽性結果的，就像以下由這份論文再製的模擬結果。可以看到不論研究者事前對自己的理論能獲得研究結果支持的賠率(Prior Odds)有多高，整體而言.005的偽陽率比.05的偽陽率少了一半。
以上的推論是建立在貝氏統計的概念之上。Benjamin等人認為以事前賠率1:10的條件來看，設.05為顯著水準的研究結果貝氏因子(Bayes Factor)會落在2.4到3.4之間，.005為顯著水準的研究結果貝氏因子大約是13.9到25.7之間。統計學者Jeffreys Harold在影響深遠的著作“Theory of Probability”(機率的理論)，認為前者表示研究結果的證據力差強人意，後者代表有起碼可觀的證據力。有此論證與72位學者中有著名的貝氏統計提倡者，像是Zoltan Dienes、Eric-Jan Wagenmakers。我第一次看完這份倡議，就有這樣的主張真正目的，是不是想引導更多人改投貝氏統計的陣營？
蘊釀兩個月的另一種聲音除了七月下旬起有一波個別學者透過私人部落格，發表支持與反對意見的浪潮。對.005主張有不同想法的學者，也在七月底於開放科學中心(Center for Open Science)主辦的SIPS研討會集結。會議結束後，由Daniel Lakens透過推特發起，集合88位世界各地的青壯世代為主的學者，一起透過網路協作，撰寫回應Benjamin等72位學者的評論“Justify your alpha”，預印本於本週一9/18正式投稿Nature Human Research並上網公開。
這份評論的基本立場是肯定必須採取消減偽陽性研究的措施，但是只從設定更嚴苛的統計顯著水準下手是不夠的。不同於Benjamin等人的主張只依賴數值模擬，Lakens等人評論以實際資料的分析做為佐證。就以研究的可再現性來說，從著名的2015年心理學再現研究專案來說，有40多份的原始研究p值是小於.005，但是只有一半能被成功再現。所以就實際的資訊來說，並不能真正有效降低偽陽性研究的產出。
採取更嚴苛的顯著水準並不只是改變解讀分析結果的標準而己，而是牽動研究工作裡的每一項操作。如一開始提到提高顯著水準，就要增加至少70%的樣本才能得到顯著結果，如此會同時提高原創研究與再現研究的成本。
對於大多數研究者來說，統計分析只是工具，在我所知道的亞洲學術圈。多數學者們的報告只有提供p值，採用更嚴格的統計水準主張，對主張內容不會深究的多數人來說，可能會想追求更小的p值，做為彰顯研究成果的價值。這應該與Benjamin等72位學者想提昇的科學研究嚴謹度，是背道而馳的局面。
微小的想法和建議因為我與Daniel Lakens等作者有在SIPS親身交流的經歷，也在評論草稿初期就加入寫作，所以忝列為88名回應者之一。其中有許多有創作力與寫作高手，評論主體並未貢獻一詞。初版草稿之中有一段討論科學價值與研究操作的問題，我發現這段的草稿寫得太偏向數值分析，讓整篇評論的調性接近Benjamin等人的倡議。所以提出個人的修改建議，也很高興被其他作者接受，而成就了最後的完稿。
我在參與經驗中再次反思華人社會科學圈的科學操作問題：運用分析資料提出理論判斷的學者，是抱著多少的事前期待看待自已的理論。像Benjamin等人的倡議與Lakens等人的回應，都是設定相對低的事前賠率(最高1:10)，討論今後研究者該採取的最佳操作。在我成長的學術環境中，卻似乎存在對自己的研究理論有相當高的信心，如1:1。這或許與多數研究是借鑒已出版的西方研究有關，但是不論是普遍的信心還是可能的原因，都沒有實際的研究資料，我的感受只是個人臆測。然而我相信這是亞洲地區的開放科學人士可以做的研究題目，可藉此找到在這樣的學術環境推廣開放科學的切入點。
最後藉Benjamin等人的倡議與Lakens等人的回應，介紹預印發表。這種發表模式在資訊科學領域從1991年起，已運作將近30年。學者在初次投稿時，就將手稿與研究材料，上傳至有公信力的資料庫公開，如arXiv，期刊尚在評審時，讀者就能閱覽論文資料。社會科學領域也在1994年出現性質類似的SSRN，近年開放科學中心為推廣開放取用(Open Access)，也建置整合多項領域的OSF Preprints，包括屬於心理學的PsyArxiv。只要期刊允許，作者可自行於這些網站公開投稿。在今年的SIPS，我就得知美國心理學學會(APA)，已經接受PsyArxiv做為APA旗下期刊發表預印本主要平台的消息。我所知道的亞洲地區本土期刊還沒有開始這樣的政策，如果有那一國出現這樣的期刊，或者有規模的支持措施開始營運，該國會成為亞洲開放科學的領導國。
</description>
    </item>
    
    <item>
      <title>「提昇你的統計推論功力」中文資源使用說明及學習指南</title>
      <link>/zh/post/text_2017009/</link>
      <pubDate>Sun, 20 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/zh/post/text_2017009/</guid>
      <description>中英字幕對照檔已於8/21上傳Coursera，有註冊Coursera的朋友可直接在平台觀看有中文字幕的影片。這份指南與教材的翻譯文本是繁體中文，大陸及港澳地區朋友，如果閱讀中無法習慣字體與詞彙用語，請多多見諒。
終於完成Coursera的課程「提昇你的統計推論功力」( Improving your statistical inferences )教材(每週課程說明，影片字幕)第一階段中文翻譯。這門課程是由荷蘭埃因霍溫科技大學副教授Daniel Lakens設計講授，於2016年10月上架。因為我從2015年起就訂閱Daniel的部落格「20%的統計學家」(The 20% Statistician )，所以首先是從他發佈的部落格貼文得知。當時我正在荷蘭進行訪問研究，也正在學習使用這門課程推廣的幾種統計分析方法，所以我就聯絡Daniel，願不願意讓更多中文世界的學者與學生們認識這門課程？他欣然接受這個點子，於使我們一起在OSF開了一份公開專案，開始了第一階段影片字幕翻譯計畫：翻譯並公開每週課程介紹與影片字幕，讓有興趣但英文閱聽能力有限的華文人士，可以理解課程內容，直接使用課程資源。並且也歡迎各方高手協助校正，為第二階段作業資源中文化工作做準備。
Daniel Lakens曾參與2015年轟動全球，不到40%心理學研究可被再現的「心理學再現研究專案」資料分析工作。Daneil因為自己博士班時期的原創研究無法被他人成功再現，決心深入學習多數心理學家幾乎不接觸的數理與生物統計學，他把學習成果轉化為多篇幫助心理學家改善研究設計與統計分析的論文。還以每篇論文為基礎，撰寫至少一篇部落格文章，這門課程可說是他整理個人近幾年研究與教學的精華。
我決定開這個坑有幾個理由，除了課程品質好，課程設計對習慣台灣系統，甚至是東亞國家的統計與研究方法教學系統的學生，都是全新的體驗。像是在課程裡安排的一段科學哲學的介紹，讓學習者了解Daneil為什麼主張視情況善用次數主義統計(Frequentist statistics)與貝氏統計(Bayesian statistics)的方法。課程中的不少案例是到2015年止，在學術界引起結果無法再現的研究。不曉得2015年為什麼會有「心理學再現研究專案」出現的朋友，上到第三週大概就會明白，這項專案並不是有一群心理學家故意找另一群心理學家的麻煩，而是為了重新喚起心理科學的求真精神。
除了幾部影片字幕是由朋友協力翻譯，我自己在參加2017年的SIPS研討會提昇心理科學協會(Society for the Improvement of Psychological Science (SIPS) Meeting )之前，完成了大部分的字幕初翻。除了想要當面向Daneil致意，也為準備參加會議活動做準備。結果真的派上用場，在其中一場設計新世代研究方法課程的黑客松裡，就直接取用了這門課的部分資料與作業。
上課前，要做什麼準備？ 除了講師的影片語言，簡介說明，參考資料與作業測驗都是英文，對於英文程度不流利的學生有些吃力。課程內容是設定決定上課的學生，有修習初級統計，並有一兩次的研究執行與資料分析經驗。這門課不會告訴你什麼是平均數還有標準差，第一週介紹完統計方法流派之後，就立刻談_p_值的意義與誤解。如果你之前還沒有學過任何推論統計方法，不只可能看不懂影片，也不會了解作業如何下手。建議有意學習者曾修過大學的基礎統計與初階研究方法，或者已修過Coursera的任何一門基礎統計課程。
本課程的許多作業都是要實際操作R與Excel試算表軟體，多數台灣社會科學領域的學生多少有一些操作Excel的經驗，但是R可能對這群學生還是高門檻的統計語言。好在台灣有許多熱心推廣R的資料科學高手，可以先找一門自學教材上手。我推薦Wush Wu設計維護的R語言翻轉教室，先熟悉一下R的使用環境與語法，就能從課程作業了解講師希望你透過操作能學到什麼東西。這門課程作業的R真的不難，只要照著題目說明，改一兩個地方就能看到執行結果。
開始課程前，先了解各週學習重點 課程共有八週，除了最後一週是提出自己的研究計畫與同學線上互評，第一週到第七週每週有三段主要視頻、一到二件數據模擬與分析作業，以及一份當週測驗卷。每週測驗卷有A/B兩種版本，是Daniel與萊登大學博士生Tim van de Zee合作設計，要收集選修這門課程的人士學習表現，分析後做為之後改進課程內容的依據。我建議修課同學，將每週的課程資料下載，並依週次建檔，之後有用時可知如何找到需要的資源。建檔結構可參考我的github儲存庫。
每門課程都有一則簡短的課程概論，說明每段視頻與作業的重點，並列出與視頻內容有關的參考文獻。七週課程概 論的中譯初稿已在公開專案上線，強烈建議初學者先閱讀課程概論，了解自已能否從影片與作業學習到Daniel要傳達給你的資訊，判斷自已需不需要尋找同儕互助學習。每週課程影片的中英對照字幕可由公開專案下載，這系列的課程影片都可以下載觀賞，英聽不夠好的同學可以下載影片和字幕，用可外掛字幕的播放軟體觀賞。
以下簡述七週學習重點與經驗：
 第一週/引言與次數主義統計：第一段介紹三種統計推論取向，後兩段的重點是討論_p_值的正確與錯誤運用方式。對於有研究經驗的同學來說，最值得仔細理解的是，有沒有曾經認為_p_值就等於研究結果型一錯誤率？有沒有以為_p_值是虛無假設成立的機率？Daniel在這週課程為你解惑。
 第二週/似然值與貝氏統計：介紹似然值與貝氏統計，這兩種統計推論方法在亞洲的許多大學統計課都從被納入。如果你曾在論文裡看過貝氏因子(BF)與可信區間(Cridible interval)，這週課程會給你一個初步的認識。Daniel推薦的書籍 Understanding Psychology as a Science ，是第一本為心理學家寫的貝氏統計入門教科書，值得找來一讀。
 第三週/有效控制推論錯誤率：延續第一週的課題，介紹有效控制型一與型二錯誤率的方法。第三段還談到如何運用這先方法，規劃可靠又有效的預先註冊研究(preregistration)。做完這週作業與測驗，你手上正好有準備執行或規劃中的方法，可以嘗試使用預先註冊會變得如何？
 第四週/效果量(effect size)專題：效果量是進行整合性分析(meta analysis)與註冊確證性研究(confirmatory research)，不可或缺的元素。你希望研究的證據力要有多高，就要先評估效果量與考驗力(power)。
 第五週/良好的樣本數估計：基礎統計就會學到的信賴區間(Confidence interval)，以及決定樣本數(Sample Size)的策略。Daniel在這週讓你認清過去從教科書或課堂學習中不足夠的地方，並介紹近幾年竄起的統計品質分析工具：p-Curve。
 第六週/科學哲學：不完全是統計課的一週。Daniel淺談科學哲學入門，以及理論的建構。最近Daniel的部落格文章提到，接下來心理科學將進入理論危機(Theory Crisis)，配合閱讀能了解這一週課程內容如此安排的用意。如果你有不知如何定義虛無假設的理論意義，這週Daniel介紹他的最愛：等效測試(equivalence testing)。
 第七週/開放科學：集中談論前六週偶爾提到的再現研究與出版偏誤，這是2015年200多位心理學家自願參與心理學再現研究專案的重要因素。最後一段展望能消除這些問題的開放科學。
  完成各週作業之後的學習方向 如果你有時間，建議完成第八週的互評作業。計畫要分析的資料不一定要親自收集，可以找有興趣主題的公開資料，測試你想檢驗的假設。我認為台灣學生可以透過這項作業，測試看看現在國內各公家機關的開放資料，能完成多少真正有意義的分析。</description>
    </item>
    
    <item>
      <title>再等等，你確定這不是「雷」研究嗎？</title>
      <link>/zh/post/text_2017008/</link>
      <pubDate>Thu, 03 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/zh/post/text_2017008/</guid>
      <description>本文印證第一手劣質科學研究，確實會被不了解如何評估品質的科普作家，當成有價值的新知。本文提出的分析與建議，適用於任何內容及情節相似的科普案例，並非針對性批判讓我得知這件案例的科普作家知識能力。
 七月底準備出國開會之前，在RSS訂閱通知看到這一篇科普文章&amp;ldquo;等等，你確定這不是假新聞嗎？&amp;rdquo;，介紹美國哥倫比亞大學商學院Johar Gita率領的團隊，發表在《美國國家科學院院刊》的事實查核的心理學研究。看到介紹文章第二段之中的一句話&amp;rdquo;研究者以一系列八個實驗來告訴大家一件事&amp;rdquo;，勾起了我的好奇心，找來原始論文一讀。讀了沒多久，發現了三件事情，讓我決定寫這篇網誌呈現我的分析，提供中文科普作者與讀者另一個觀點：
1. 這篇論文的責任編輯是Susan Fisk。
2. 八個實驗的後七個是第一個實驗的概念性再現，一致的實驗方法是受試者瀏覽網頁新聞標題，察覺其他參與者的存在，便會降低進行事實查核的意願。但是多數實驗結果p值在0.05到0.01之間。
3. 肉眼掃過前三項實驗的統計數據，便發現有瑕疵的自由度。
超過一成的統計數據瑕疵 察覺第三件事情的當下，我立刻開啟statcheck網頁，將全文pdf檔上傳，分析其中可能有錯的統計數據。下載輸出結果之後，發現statcheck從60項數據挑出9項錯誤。一篇論文有超過一成的統計錯誤有多嚴重？根據荷蘭蒂爾堡大學開發statcheck的團隊研究，1985到2013年頂尖心理學期刊出版的論文，數據出錯的比例約10%。哥大商學院用一篇論文馬上達成心理學家累積30年的成就，當然要仔細檢查真正的證據力到底有多高？為何出現這麼多錯誤的論文可以在影響係數名列前茅的《美國國家科學院院刊》發表？(註1)
整體結果缺乏證據力 還好八項實驗的主要實驗變項的統計數據並未出錯。如果有錯，這篇論文一開始就不該被接受。也許是研究者的想法有新意，基本操作與測量並未有太大問題，才會獲得責任編輯的青睞。但是八項實驗結果一致，能代表這篇論文的論點獲得充分的證據支持嗎？
為此，我把八項實驗的主要變項效果統計值與p值挑出來，進行p-Curve分析(註2)。結果顯示這八項實驗結果並沒有達到最低標準的證據力，但也沒有刻意被灌水，正如以下圖表所示：
統計檢定力是指這些實驗讓其他人完整地重做一次，結果能成功重現的機率。學過基本統計應知道統計學家Cohen建議，穩定的研究結果應具備80%的統計檢定力。20%看似有點希望，但實際上50%的實驗結果就很難重現，所以從統計學的觀點，這篇論文的結論並不能成為有價值的科學知識。
為何責任編輯會影響論文品質？ 證據力如此低的論文得以發表，期刊編輯的角色絕對不可小覷。我之前介紹的披薩門事件，曾提過方法學恐怖份子一詞得名於Susan Fisk的言論。先前在2014年，Susan Fisk也是同一本期刊備受爭議的臉書研究責任編輯。這項臉書研究的爭議除了讓臉書使用者未事先知情，就參與研究的研究倫理瑕疵，研究方法是另一個被批評的重點。這項研究收集分析約15萬5千名臉書使用者的資料，得到的實驗結果效果量卻是超乎尋常的低(0.001)。這種研究方法和結果就像為了找到蘊藏在中央山脈裡的一克拉鑽石，把整個中央山脈剷平。
繼去年創造方法學恐怖份子一詞，Susan Fisk今年更在《心理科學期刊》發表的文章，直接點名批判為首的兩名學者：哥倫比亞大學統計學教授Andrew Gelman、多倫多大學社會心理學家Ulrich Schimmack，批評他們訴諸情緒式批判，破壞科學討論的氣氛，妨礙她所相信的好科學發展。
Susan Fisk今年發表的這篇文章提到她所謂的好科學發展，是建立在良性競爭的社群、嚴謹的研究態度、與彼此互信的討論風氣等三項基礎之上。然而，看看Susan Fisk負責編輯的臉書與事實查核研究，顯然都與嚴謹(Rigor)沾不上邊。被她所批評的學者所持的批判基調，其實是指出沒有穩定的研究結果，就沒有彼此互信的基礎，卻被Susan Fisk代表的一些學者視為人身攻擊的言論。這種不同陣營各說各話的狀況，在一時之間難以平息。然而，品質不良的研究仍然有冒出頭的空間，絕非科學社群與大眾之福。
給中文科普作家的建議 科學文獻經過科普作家與記者的文字轉化，讓大眾得知有用又有趣的最新知識，對研究者與大眾是雙方受益的好事。然而需要妥善設計與嚴謹統計分析的研究，像是心理學，內部已有檢討反省多數研究是劣質操作結果的聲浪。在劣質科學研究尚待清理之際，筆者提出兩道給中文科普作家提昇專業的建議。
 提昇科普作家的統計警覺：本文示範的statcheck與p-Curve分析，都是有電腦操作經驗者皆可操作的工具。但是要了解使用時機與解讀方法，就需要掌握一定程度的統計知識，我建議有心長期經營的科普作家，要不斷充實統計知識，提昇自已的察覺能力。國內各大學有開設科普課程的系所，更應鼓勵甚至要求學生，要有持續自學統計知識的能力(註3)。
不久前有72位社會科學領域的資深學者，共同掛名即將發表在自然期刊的論文，向相關領域同行倡議，此後將統計檢定的顯著水準設為0.005，其中一個目的就是防止像哥大商學院的這種研究，有冒出頭的機會。
 選擇經同行評審的註冊研究，作為報導素材：我強調有同行評審的註冊研究，才是有起碼品質的科學研究。因為沒有同行評審就執行的註冊研究，還是有可能被不嚴謹的研究者利用，並被標準寬鬆的期刊編輯接受。實際案例如幾個月前台灣學者發表在演化心理學期刊的研究，研究內容涉及兩性對女性身體的性衝動差異，雖有自主再現的註冊實驗，但是未經同行評審，研究成果招致國內外一致的負評。
有同行評審的註冊研究很好辦識，在論文doi指向的網頁，有看到下面這個圖示便是：
  註1:除了自行上傳pdf檔到statcheck網頁，讀者可點此下載分析結果。
註2:p-curve的解讀請見我之前的文章。讀者可點此連結，看到我輸入p-Curve的數據，並能按鈕到p-Curve.com，見到和本文呈現一模一樣的圖表。
註3:個人推薦的自學課程是Coursera的Improving your statistical inferences。我與課程講師Daniel Lakens約定的影片字幕中譯已完成95%。全部完成時，我會撰寫專文介紹這門課程。</description>
    </item>
    
    <item>
      <title>JASP~操作像SPSS的程序可重製統計開源軟體</title>
      <link>/zh/post/text_2016007/</link>
      <pubDate>Tue, 10 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>/zh/post/text_2016007/</guid>
      <description>趁著這陣子台灣最高學府的學術醜聞細節不斷浮出，許多經常使用統計軟體分析資料的人士多少會回憶使用套裝統計軟體的痛苦經驗。像是都用SPSS，分析同一份資料，為什麼學長姐能跑出顯著結果，我怎麼調都做不出相同的結果。如果你有類似的際遇，就值得認識這套開源統計軟體JASP，並且試著今天就開始更新手上的統計工具。
JASP的開發團隊 JASP是由荷蘭阿姆斯特丹大學心理學系教授Eric-Jan Wagenmakers(以下簡稱EJ)主持的實驗室，以及長期合作的程式設計師一起開發與更新。EJ研究貝式統計學的應用多年，2014年出版為認知科學研究而寫的教學書藉Bayesian Cognitive Modeling，也開始JASP的開發以及每年定期舉辦工作坊。JASP的核心是R套件BayesFactor，由Richard Morey等三位計量心理學者為讓R使用者能簡易計算貝式因子(Bayes Factor)而開發，所以JASP從一開始就走開源之道。Richard Morey也是JASP開發團隊核心成員，也和EJ一起擔任工作坊講師。 因為核心成員是貝式統計的專家，JASP不僅能做傳統的統計，簡單實驗的貝式統計，如比較兩組平均數的貝式因子，都可以用JASP計算，並且操作方式與SPSS一樣，所以就算你還不明白貝氏因子，甚至也不甚了解貝式定理，也可以用手上資料計算貝式因子。EJ已公佈工作坊教材，有心的讀者可運用。本文採用EJ今年的代表作，臉部回饋表情假設經典實驗的再現研究，做個初步示範與說明。
入門影片示範 JASP的下載與安裝與一般開源軟體完全相同，有windows，Mac與Linux三種平台版本。有意使用的讀者可以從官網下載適合個人作業系統的版本。如何開始第一次使用，官網有工程師的youtube示範影片，雖然現在的版本0.8.0.0比示範影片的新，但是操作都是相同的，最新版可做初階因素分析，所以有問卷資料要分析的讀者可以試試看。 注得一提的是輸出結果檔能上傳OSF，可以直接在專案網頁瀏覽，而且其它使用者下載結果檔，用自已的JASP打開後，可以檢視及調整原作者的軟體設定。細節可參考官網影片示範。如此一來，實驗室的學長姐畢業後，能無痛交接給學弟妹了。
使用示範：重製Strack RRR 我曾在之前的文章介紹臉部回饋表情假設的再現研究，EJ是這項研究的總主持人，也負責主要的分析工作。實驗設計細節請參考前文，我以此研究為例，簡單介紹貝式因子的計算與解讀方法。
貝式因子簡介 貝式因子是一筆資料在兩個機率分配之內的似然性比值(likelihood ratio)。這兩個機率分配就是進行假設檢定時，分別代表虛無假設($ H_0 $)與對立假設($ H_1 $)的機率分配，似然性指一筆資料在某個假設為真的情況，支持這項假設的証據強度。如果對於似然性尚未有足夠的認識，可當作兩種似然性數值對應假設檢定的p值與考驗力。
兩個似然性相除表示這項證據支持一種假設的強度是支持另一種假設的多少倍。以虛無假設的似然性除以對立假設的似然性，得到的貝氏因子通常寫成$ BF_0 $$ _1 $；以對立假設的似然性除以虛無假設的似然性，得到的貝氏因子通常寫成$ BF_1 $$ _0 $。研究者要報告那一種貝氏因子，可根據這次研究看中那種假設應該得到研究結果的支持。通常原創研究會報告$ BF_0 $$ _1 $，根據之前的研結果或認定存在某種效果，都會以$ BF_1 $$ _0 $進行推論。
統計學者Kass與Raftery在1995年提出貝式因子數值的強度分界：貝氏因子至少大於1，代表位於分子的假設與位於分母的假設有起碼的差異；貝氏因子大於3，代表手上的證據正面支持位於分子的假設；貝氏因子大於20，手上證據強烈支持位於分子的假設；到了大於150，可以說沒有反證能推翻位於分子的假設。
以直接再現研究來說，已有支持臉部肌肉回饋假說的原始研究結果，自然有興趣知道再現結果的$ BF_1 $$ _0 $會不會至少大於1。此外，根據貝式定理，計算貝式因子或似然性數值需要先得知假設的先驗機率，也就是不論有無證據，假設認定的效果確實存在的機率分配。傳統的統計方法不會處理這一塊，我規畫撰寫一篇較深入的文章介紹，現在讀者只要知道JASP給了一個方便法門–預設先驗機率(default prior)。因為也是兩個假設的比值，又可稱先驗機率賠率。好比一場賽馬比賽，有兩匹初次上場的賽馬，沒有人知道那匹馬會勝出，只能由馬匹的出身背景先做推估，下注者就得到誰勝誰負的賠率。EJ在2012年發表的論文，主張預設先驗機率賠率可設為0.707，這也是打開JASP的貝氏統計程序，會看到的預設值。
臉部肌肉回饋假說的實驗，就像「牙齒組評分高於嘴唇組評分」與「牙齒組評分等於嘴唇組評分」兩個可能結果，在一間實驗室裡同場較量。0.707代表未做實驗之前，對前者的看好度是後者的0.707倍，貝式因子表示完成實驗之後，這間實驗室判定前者真正勝過或負於後者的比例。所以貝式因子至少大於1，表示「牙齒組評分高於嘴唇組評分」確實比「牙齒組評分等於嘴唇組評分」早一點點抵達終點線。17個實驗室的貝式因子都沒有大於1，表示臉部肌肉回饋假說看好的結果都沒有真正勝過沒有差異的結果。
取用重製成果 臉部肌肉回饋假說再現研究的所有資料，已公開於OSF專案，論文的表2記綠所有17個實驗室結果的貝氏因子。產生論文中所有圖表的原始資料與分析腳本壓縮檔下載後，可重製論文中的所有圖表。不過我發現重製出來的貝氏因子和論文表2有些出入，可比較下圖與原始表格：
為何自已跑出來的結果有些許不同，我會去信向EJ詢問。但是讀者們可以像我一樣，用JASP重製單側假設檢定的貝氏因子，只要下載我的jasp檔，了解我的重製方法。
經由可重製分析流程學習與使用統計 由於原始實驗室曾發生「牙齒組評分高於嘴唇組評分」勝出的事實，所以EJ在這次再現研究嘗試一種為評估再現研究信效度而開發的貝式因子，在2014年發表的論文，提到以原始研究的統計值為種子，取得逼近合理先驗機率賠率的方法。這套演算方法尚未收錄於任何套件，所以現版本的JASP未能重製。然而論文表2顯示，只有Zeelenberg的實驗室出現「牙齒組評分高於嘴唇組評分」稍微勝出的結果。上圖的再製表格卻無法再現相同的分析結果。
透過這次重製經驗，即使我未能完全了解論文中的公式推導，卻能從公開的程式碼，了解這套演算方法的邏輯。相信有心提昇個人統計功力的讀者，也能透過這樣的方式學習觀念與工具。
本文隨JASP重要升級持續更新 JASP 1.0還未正式推出，未來更新有何變化尚未可知，因此本文內容如果因為將來的更新而有改變，會進行相對的更新與修正。有興趣學習的JASP與貝式統計的讀者，可以到EJ常駐的網路論壇提問，與EJ及其它高手直接交流。</description>
    </item>
    
  </channel>
</rss>