<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R_programming | Sau-Chin Chen&#39;s website</title>
    <link>/tags/r_programming/</link>
      <atom:link href="/tags/r_programming/index.xml" rel="self" type="application/rss+xml" />
    <description>R_programming</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Thu, 11 Jan 2018 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>R_programming</title>
      <link>/tags/r_programming/</link>
    </image>
    
    <item>
      <title>Use bookdownplus write papers and manage lab logs</title>
      <link>/post/use-bookdownplus/</link>
      <pubDate>Thu, 11 Jan 2018 00:00:00 +0000</pubDate>
      <guid>/post/use-bookdownplus/</guid>
      <description>


&lt;p&gt;Since being a Rmarkdown user, I’m thinking how to write papers, manage teaching materials and record lab works in this format. When I met &lt;a href=&#34;https://github.com/crsh/papaja&#34;&gt;&lt;code&gt;papaja&lt;/code&gt;&lt;/a&gt;&lt;span class=&#34;citation&#34;&gt;(Aust and Barth 2017)&lt;/span&gt; three years ago, it is my dream someday I will use &lt;code&gt;R&lt;/code&gt;&lt;span class=&#34;citation&#34;&gt;(R Development Core Team 2010)&lt;/span&gt; process all my works. &lt;code&gt;papaja&lt;/code&gt; is amazing but it is implemented to English only. Later I found &lt;a href=&#34;https://bookdown.org/yihui/bookdown/get-started.html&#34;&gt;&lt;code&gt;bookdown&lt;/code&gt;&lt;/a&gt; developed by Yihui Xie&lt;span class=&#34;citation&#34;&gt;(Xie 2017)&lt;/span&gt;. &lt;code&gt;bookdown&lt;/code&gt; has the potential to manage Chinese writings. However, this package is primarily developed for writing and publishing books.&lt;/p&gt;
&lt;p&gt;Fortunately, &lt;a href=&#34;http://www.pzhao.org/zh/&#34;&gt;Peng Zhao&lt;/a&gt; has worked on the advanced work: &lt;a href=&#34;https://github.com/pzhaonet/bookdownplus&#34;&gt;&lt;code&gt;bookdownplus&lt;/code&gt;&lt;/a&gt;&lt;span class=&#34;citation&#34;&gt;(Zhao 2017)&lt;/span&gt;. This package provides many templates for a couple of academic works and hobbies. According to the help file, there are &lt;code&gt;academic article&lt;/code&gt;, &lt;code&gt;book&lt;/code&gt;, &lt;code&gt;thesis&lt;/code&gt;, &lt;code&gt;poster&lt;/code&gt;, and &lt;code&gt;journals&lt;/code&gt;. Because of Zhao’s interests, the users could write and publish &lt;code&gt;poem book&lt;/code&gt; and &lt;code&gt;guitar chords&lt;/code&gt;. The following pictures are the outcomes of these templates:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pzhaonet/bookdownplus/master/inst2/showcase/bookdownplus_article.jpg&#34; title=&#34;academic article&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pzhaonet/bookdownplus/master/inst2/showcase/bookdownplus_yihui_zh.jpg&#34; title=&#34;book&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pzhaonet/bookdownplus/master/inst2/showcase/bookdownplus_thesis_classic.jpg&#34; title=&#34;thesis&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pzhaonet/bookdownplus/master/inst2/showcase/bookdownplus_poem.jpg&#34; title=&#34;poster&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pzhaonet/bookdownplus/master/inst2/showcase/bookdownplus_journal.jpg&#34; title=&#34;journal&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pzhaonet/bookdownplus/master/inst2/showcase/bookdownplus_poster.jpg&#34; title=&#34;poem book&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pzhaonet/bookdownplus/master/inst2/showcase/bookdownplus_guitar.jpg&#34; title=&#34;guitar&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I believe ‘journal’ will be the hottest templaters for many research teams who are running their open practices. All the members of a project will have managed their daily journals collaboratively. The journal could be opened to public after the final paper is formly published.&lt;/p&gt;
&lt;p&gt;For the users who read and write traditional Chiense like me, you have to install some font files after you completed the install work flow as the mannual. According to my tests in WINDOWS 10, The font files are &lt;code&gt;KaiTi.ttf&lt;/code&gt;, &lt;code&gt;simfang.ttf&lt;/code&gt;, &lt;code&gt;simhei.ttf&lt;/code&gt;, and &lt;code&gt;simkai.ttf&lt;/code&gt;. Then you can use the Chinese templates in &lt;code&gt;bookdownplus&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;In future, I wish &lt;code&gt;bookdownplus&lt;/code&gt; could enhance the support for many multi-bytes language systems. The users could provide and share the customed templates through the updates. This will be the handy tool for the open scientists out of WIERD world.&lt;/p&gt;
&lt;div id=&#34;reference&#34; class=&#34;section level3 unnumbered&#34;&gt;
&lt;h3&gt;Reference&lt;/h3&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-AustpapajaReproducibleAPA2017&#34;&gt;
&lt;p&gt;Aust, Frederik, and Marius Barth. 2017. &lt;em&gt;Papaja: Reproducible APA Manuscripts with R Markdown&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-RDevelopmentCoreTeamlanguageenvironmentstatistical2010&#34;&gt;
&lt;p&gt;R Development Core Team. 2010. “R: A Language and Environment for Statistical Computing.” Vienna, Austria: R Foundation for Statistical Computing.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-XiebookdownAuthoringBooks2017&#34;&gt;
&lt;p&gt;Xie, Yihui. 2017. &lt;em&gt;Bookdown: Authoring Books and Technical Documents with R Markdown&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-ZhaobookdownplusTextbook2017&#34;&gt;
&lt;p&gt;Zhao, Peng. 2017. &lt;em&gt;R Bookdownplus Textbook&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Rethink Significance</title>
      <link>/post/2016-05-05-rethink-significance/</link>
      <pubDate>Thu, 05 May 2016 00:00:00 +0000</pubDate>
      <guid>/post/2016-05-05-rethink-significance/</guid>
      <description>


&lt;p&gt;To trace the fallacy of use hypothesis testing, I am programming the examples in Dr. Adrianus D. de Groot’s paper &lt;code&gt;The meaning of “signiﬁcance” for different types of research&lt;/code&gt;. This paper is published in 1956 in the Dutch journal &lt;em&gt;Nederlands Tijdschrift voor de Psychologie en Haar Grensgebieden&lt;/em&gt;. &lt;a href=&#34;https://en.wikipedia.org/wiki/Adriaan_de_Groot&#34;&gt;Adrianus De Groot&lt;/a&gt; is Dutch psychologist and chess master. During 1950s and 1960s, he suggested the concept of emperical cycle for the researchers who use the statistical tools in the social and behavioral researches.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/images/524px-Empirical_Cycle.png&#34; title=&#34;A visual representation of A.D. de Groot&amp;#39;s empirical cycle. Author: TesseUndDaan&#34; alt=&#34;Emperical cycle&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Emperical cycle&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;de Groot’s emperical cycle distinguish two types of emperical research: &lt;strong&gt;exploratory research&lt;/strong&gt; and &lt;strong&gt;confirmatory research&lt;/strong&gt;. &lt;strong&gt;Exploratory research&lt;/strong&gt; aims to formulate the hypotheses that covers the process from &lt;code&gt;observation&lt;/code&gt; to &lt;code&gt;induction&lt;/code&gt;. &lt;strong&gt;Confirmatory research&lt;/strong&gt; attempts to test the predicited concequences based the hypothesis. Thus a &lt;strong&gt;Confirmatory research&lt;/strong&gt; covers &lt;code&gt;deduction&lt;/code&gt;, &lt;code&gt;testing&lt;/code&gt;, and &lt;code&gt;evaluation&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;In the time de Groot started his academic career, the protocol of hypothesis testing has been completed by the leading statisticans, &lt;a href=&#34;https://en.wikipedia.org/wiki/Ronald_Fisher&#34;&gt;Ronald Fisher&lt;/a&gt;, &lt;a href=&#34;https://en.wikipedia.org/wiki/Jerzy_Neyman&#34;&gt;Jerzy Neyman&lt;/a&gt;, and &lt;a href=&#34;https://en.wikipedia.org/wiki/Egon_Pearson&#34;&gt;Egon Pearson&lt;/a&gt;. Psychologists at that time learned and used &lt;em&gt;p value&lt;/em&gt; to evaluate the results. de Groot in his paper has suggested that the hypothesis testing is the appropriate tool to evaluate the result of a confirmatory reserach. He in the same paper also discussed the problems that perhapes happen when the hypothesis testing was used to decide the available hypotheses in an exploratory research. There are two cases of explorartoy research discussed in his paper. One has finite hypotheses, and the other has infinite hypotheses. Both cases show up in front of every researcher in anytime and in anywhere. Many researcher struggle how to pick the available hypotheses up according to the data in hands.&lt;/p&gt;
&lt;div id=&#34;exploratory-research-has-finite-hypotheses&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Exploratory research has finite hypotheses&lt;/h3&gt;
&lt;p&gt;The section title in de Groot’s paper is &lt;code&gt;Hypothesis testing research for multiple hypotheses&lt;/code&gt;. He presumed the case as follow:&lt;/p&gt;
&lt;p&gt;We give &lt;em&gt;N&lt;/em&gt; as the number of hypotheses yet to be tested. Every hypothesis is going to be evaluated by the hypothesis testing. We also give &lt;em&gt;n&lt;/em&gt; as the number of hypothese successfully passed the test. Every hypothesis have the probability .05 pass the test. This probability refers to the type 1 error in the present hypothesis testing.&lt;/p&gt;
&lt;p&gt;Today we have 10 hypotheses (N = 10) to be evaluated by the data. Consider all the consequences, we can calculate all the probabilities given the counts of positive hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;require(xtable)
N &amp;lt;- 10
n &amp;lt;- 0:10
alpha &amp;lt;- .05
REJECT_P &amp;lt;- 0
PASS_P &amp;lt;- rep(0,length(n))
for(k in n){
        REJECT_P = REJECT_P + choose(N,k)*alpha^k*(1 - alpha)^(N - k) 
        PASS_P[k+1] = 1 - REJECT_P
}
SUCCESS = data.frame(n,PASS_P)
colnames(SUCCESS) &amp;lt;- c(&amp;quot;n&amp;quot;, &amp;quot;Probability(Positive Results)&amp;quot;)
print(xtable(SUCCESS), include.rownames = FALSE, type = &amp;quot;html&amp;quot; ) &lt;/code&gt;&lt;/pre&gt;
&lt;!-- html table generated in R 3.6.2 by xtable 1.8-4 package --&gt;
&lt;!-- Tue Jan 28 21:19:11 2020 --&gt;
&lt;table border=&#34;1&#34;&gt;
&lt;tr&gt;
&lt;th&gt;
n
&lt;/th&gt;
&lt;th&gt;
Probability(Positive Results)
&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;
0
&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;
0.40
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;
1
&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;
0.09
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;
2
&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;
0.01
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;
3
&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;
0.00
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;
4
&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;
0.00
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;
5
&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;
0.00
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;
6
&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;
0.00
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;
7
&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;
0.00
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;
8
&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;
0.00
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;
9
&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;
0.00
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;
10
&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;
0.00
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(PASS_P ~ n, xlab = &amp;quot;Smallest Number of Positive Hypotheses&amp;quot;, ylab = &amp;quot;Probability(Positive Results)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/en/post/2016-05-05-rethink-significance_files/figure-html/MultiHypo-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;That table is telling us if we wish acquire at least one positive hypothesis, the probability is 0.4012631. That plot shows the probability dramatically decrease with the increasing numbers in our wish. In other words, when we have no precise knowlegde about the use of hyphtesis testing, the more hypotheses we want to induce, the higher risk we get nothing.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;exploratory-research-has-infinite-hypotheses&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Exploratory research has infinite hypotheses&lt;/h3&gt;
&lt;p&gt;This case is everywhere in this era of big data. de Groot called this case &lt;code&gt;Material-exploration: N becomes unspeciﬁed&lt;/code&gt;. In his paper, material refers to data because data is a low frequency word in his era. The researchers in his era has realized the best way to deal with this case is &lt;strong&gt;to let the data tell the story&lt;/strong&gt;. The research on this case obviously is an &lt;strong&gt;exploratory research&lt;/strong&gt;. For the researchers in de Groot’s era and in the era of big data, there are two routes to finish this kind of research project. One route is to label and categorize the hypotheses. This route is the hot topic of &lt;a href=&#34;https://en.wikipedia.org/wiki/Machine_learning&#34;&gt;machine learning&lt;/a&gt; in the present data science. The other route is to decide the possible hypotheses. Today the researchers on this route mostly rely on the multiple variate statistical tools.&lt;/p&gt;
&lt;p&gt;de Groot suggests the caution to the research that attempts to decide the potential hypotheses. &lt;strong&gt;N&lt;/strong&gt; is infinite because not all hypotheses could be induced in this case. Whe we have 20 testable hypotheses from 200 potential hypotheses. If a researcher confirmed that 10 of the 20 hypotheses have the positive support by the data, based on the type 1 error, he/she has to understand that 5% hypotheses are positive (10/200) but 50% hypotheses are positive (10/20). This caution is like the misuse of golem that is discussed in &lt;a href=&#34;https://www.crcpress.com/Statistical-Rethinking-A-Bayesian-Course-with-Examples-in-R-and-Stan/McElreath/9781482253443&#34;&gt;Statistical Rethingking&lt;/a&gt;. In the timing I am writing this note, this caution implied the researchers who are thinking the potential hypotheses are decided assumed that they have finished a emperical circle.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;role-of-preregisteration&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Role of Preregisteration&lt;/h3&gt;
&lt;p&gt;Decades of misusing the hypothesis testing have resulted in a bad situation we have to faced. There is no clear cutoff between the exploratory research and the confirmatory research. Many published papers in nature are the exploratory researches, but they are packaged in the form of confirmatory research by the authors (editors and reviewers have the responsibility too). This is why de Groot’s originated paper was translated and published 60 years later. This post is one of the fundemental I will cite when I introduce and discuss the preregistration.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Check My Tools to Create and Manipulate Golems</title>
      <link>/post/2016-04-22-check-my-tools-to-create-and-manipulate-golems/</link>
      <pubDate>Fri, 22 Apr 2016 00:00:00 +0000</pubDate>
      <guid>/post/2016-04-22-check-my-tools-to-create-and-manipulate-golems/</guid>
      <description>


&lt;p&gt;Since two weeks before I published this post, I have started read the book &lt;a href=&#34;http://xcelab.net/rm/statistical-rethinking/&#34;&gt;Statistical Rethinking: A Bayesian Course with Examples in R and Stan&lt;/a&gt; written by &lt;a href=&#34;http://xcelab.net/rm/&#34;&gt;Richard McElreath&lt;/a&gt;. Richard is the evolutionary anthropologist at Max Planck Institute. He wrote this textbook for the PhD students who will use the Bayesian statistics in their research projects. Compared to the textbooks written by statisians and data scientistst, Richard’s book explain and demonstrate the statistical methods with examples instead of equations. His intention is to help who are not staticians but used to use statistics realize one fact: we rely on the statistical models as the representations of our answers rather than answer the questions by the raw data or naked truth. Many non-statisticians are used to find and learn what kind of methods or apps to deal with their data, but few are interested to know the models under the mentods and apps they are using. The trouble and danger is that they thought their jobs are done when the program printed the tables and figures but these outputs are from the statistical model is unable to answer their question. This situation is originated from many non-statisticans consider themselves the end-users of statistical models. Like any user of a packaged software, non-statisticans have no time to understand how the tools in their hands designed and conducted by statisticans.&lt;br /&gt;
Richard introduced the story of &lt;a href=&#34;https://en.wikipedia.org/wiki/Golem&#34;&gt;golem&lt;/a&gt; to raise the non-statsiticans’ attention to the troubles they had made and will make. A statistical model, like a golem, has the power beyond human to finish the work the human are unable to do, for example, trace the passengers’ track from the trillion of camera. Its power could be misused or out of control if we do not understand what is the root of its action. A user of ststistical method, no matter you are or are not stistician, have to keep the awareness of engineer when you are dealing with your data. Today everyone has many easier ways than a decade ago to keep the awareness of engineer. One advantage is that the learning curve for being an part-time hacker is getting smooth. Increasing R apps are opening many windows for who are want to outlook and modify the statistical models.&lt;br /&gt;
Since this post, every post listed in the category &lt;code&gt;Rethinking&lt;/code&gt; is one of the summaries and feedbacks to &lt;a href=&#34;https://www.crcpress.com/Statistical-Rethinking-A-Bayesian-Course-with-Examples-in-R-and-Stan/McElreath/9781482253443&#34;&gt;Statistical Rethinking: A Bayesian Course with Examples in R and Stan&lt;/a&gt;. At first I have to check my toolkits for create and manipulate the statistical models. They are R core and the packages. Years ago I have used to use the packages in my data processing. Now I show them for who start to use R after read this post.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;install.packages(c(&amp;quot;rpart&amp;quot;,&amp;quot;chron&amp;quot;,&amp;quot;Hmisc&amp;quot;,&amp;quot;Design&amp;quot;,&amp;quot;Matrix&amp;quot;,&amp;quot;stringr&amp;quot;,&amp;quot;lme4&amp;quot;,&amp;quot;coda&amp;quot;,&amp;quot;e1071&amp;quot;,&amp;quot;zipfR&amp;quot;,&amp;quot;ape&amp;quot;,&amp;quot;languageR&amp;quot;,&amp;quot;multcomp&amp;quot;,&amp;quot;contrast&amp;quot;,&amp;quot;shiny&amp;quot;,&amp;quot;ggplot2&amp;quot;, &amp;quot;dplyr&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Some of the packages are learned from I participated in &lt;a href=&#34;https://www.coursera.org/specializations/jhu-data-science&#34;&gt;Cousera Data Science&lt;/a&gt;. Now I used to use &lt;code&gt;dplyr&lt;/code&gt; to process the raw data, and I am learning how to draw the figures I need in use of &lt;code&gt;ggplot2&lt;/code&gt;. When this post is published, I have updated my R to R version 3.6.2 (2019-12-12). Through &lt;a href=&#34;http://xcelab.net/rm/statistical-rethinking/&#34;&gt;the codes of Heuristic Andrew&lt;/a&gt;, here are my installed packages.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ip &amp;lt;- as.data.frame(installed.packages()[,c(1,3:4)])
rownames(ip) &amp;lt;- NULL
ip &amp;lt;- ip[is.na(ip$Priority),1:2,drop=FALSE]
print(ip, row.names=FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##              Package     Version
##                abind       1.4-5
##              acepack       1.4.1
##                 afex      0.26-0
##           ANOVApower       0.0.3
##              anytime       0.3.7
##                  apa       0.3.2
##                  arm      1.10-1
##              askpass         1.1
##           assertthat       0.2.1
##            backports       1.1.5
##            base64enc       0.1-3
##          BayesFactor  0.9.12-4.2
##           bayestestR       0.5.0
##                   BH    1.72.0-3
##               bibtex     0.4.2.2
##                bindr       0.1.1
##             bindrcpp       0.2.2
##               binman       0.1.1
##                binom       1.1-1
##               bitops       1.0-6
##             blogdown        0.17
##             bookdown      0.17.2
##                 brew       1.0-6
##       bridgesampling       0.8-1
##          Brobdingnag       1.2-6
##                broom       0.5.3
##          broom.mixed       0.2.4
##           broomExtra       1.0.1
##                   ca        0.71
##                callr       3.4.0
##                  car       3.0-6
##              carData       3.0-3
##              caTools      1.18.0
##                cdata       1.1.5
##           cellranger       1.1.0
##            checkmate       1.9.4
##             circlize       0.4.8
##                 citr       0.3.2
##                  cli       2.0.1
##                clipr       0.7.0
##           clisymbols       1.2.0
##                 coda      0.19-3
##                 coin       1.3-1
##           colorspace       1.4-1
##         colourpicker         1.0
##           commonmark         1.7
##           compute.es       0.2-4
##             contfrac      1.1-12
##                 covr       3.4.0
##              cowplot       1.0.0
##               crayon       1.3.4
##            crosstalk       1.0.0
##                 crul       0.9.0
##                 curl         4.3
##           data.table      1.12.8
##                  DBI       1.1.0
##               dbplyr       1.4.2
##                 desc       1.2.0
##            DescTools     0.99.32
##              deSolve      1.27.1
##             devtools       2.2.1
##          DiceKriging       1.5.6
##            dichromat       2.0-0
##               digest      0.6.23
##                dplyr       0.8.3
##                   DT        0.11
##           effectsize       0.0.1
##              effsize       0.7.6
##              ellipse       0.4.1
##             ellipsis       0.3.0
##             elliptic       1.4-0
##              emmeans    1.4.3.01
##                  EMT         1.1
##         estimability         1.3
##             evaluate        0.14
##                 expm     0.999-4
##            extrafont        0.17
##          extrafontdb         1.0
##                   ez       4.4-0
##                fansi       0.4.1
##               farver       2.0.3
##              fastmap       1.0.1
##                 faux  0.0.0.9013
##              fauxpas       0.2.0
##        flexdashboard     0.5.1.1
##            flextable       0.5.6
##              forcats       0.4.0
##              foreach       1.4.7
##              Formula       1.2-3
##                   fs       1.3.1
##        gameofthrones       1.0.0
##               gargle       0.4.0
##                gdata      2.18.0
##              gdtools       0.2.1
##             generics       0.0.2
##            geosphere      1.5-10
##              getPass       0.2-2
##               GGally       1.4.0
##           ggcorrplot       0.1.3
##            ggeffects      0.14.0
##              ggExtra         0.9
##              ggforce       0.3.1
##                  ggm         2.3
##                ggmap       3.0.0
##              ggplot2       3.2.1
##               ggraph       2.0.0
##              ggrepel       0.8.1
##             ggridges       0.5.2
##             ggsignif       0.6.0
##          ggstatsplot       0.1.4
##             ggthemes       4.2.0
##                   gh       1.0.1
##                git2r      0.26.1
##              glmmTMB       0.2.3
##        GlobalOptions       0.1.1
##                 glue       1.3.1
##                  gnm       1.1-0
##          googledrive       1.0.0
##         googlesheets       0.3.0
##        googlesheets4       0.1.0
##          GPArotation   2014.11-1
##               gplots     3.0.1.2
##         graphlayouts       0.5.0
##            gridExtra         2.3
##         groupedstats       0.1.1
##                  gsl       2.1-6
##               gtable       0.3.0
##               gtools       3.8.1
##          harrypotter       2.1.0
##                haven       2.2.0
##                headR       0.1.1
##                 here         0.1
##                highr         0.8
##                Hmisc       4.3-0
##                  hms       0.5.3
##           hrbrthemes       0.6.0
##             htmldeps       0.1.1
##            htmlTable      1.13.3
##            htmltools       0.4.0
##          htmlwidgets       1.5.1
##             httpcode       0.2.0
##               httpuv       1.5.2
##                 httr       1.4.1
##             hunspell         3.0
##             hypergeo      1.2-13
##               igraph     1.2.4.2
##                  ini       0.3.1
##               inline      0.3.15
##              insight       0.8.0
##             installr      0.22.0
##             ISOcodes  2019.12.22
##            iterators      1.0.12
##          janeaustenr       0.1.5
##              jcolors       0.0.4
##                  jmv       1.0.8
##           jmvconnect       1.0.9
##              jmvcore       1.0.8
##                 jpeg     0.1-8.1
##             jsonlite         1.6
##             jspsychr  0.0.0.9000
##           kableExtra       1.1.0
##                knitr        1.27
##               koRpus      0.11-5
##       koRpus.lang.en       0.1-3
##             labeling         0.3
##        LaplacesDemon      16.1.1
##                later       1.0.0
##         latticeExtra      0.6-29
##               lavaan       0.6-5
##             lazyeval       0.2.2
##              leaflet       2.0.3
##    leaflet.providers       1.9.0
##              libcoin       1.0-5
##            lifecycle       0.1.0
##                 lme4      1.1-21
##               lme4.0  0.999999-4
##             lmerTest       3.1-1
##               lmtest      0.9-37
##            logspline      2.1.15
##                  loo       2.2.0
##            lubridate       1.7.4
##                 lutz       0.3.1
##               magick         2.2
##             magrittr         1.5
##              mapproj       1.2.6
##                 maps       3.3.0
##             maptools       0.9-9
##             markdown         1.1
##           matrixcalc       1.0-3
##         MatrixModels       0.4-1
##          matrixStats      0.55.0
##                MBESS       4.6.0
##                 mc2d      0.1-18
##              memoise       1.1.0
##                MEMSS       0.9-3
##              metaBMA       0.6.2
##              metafor       2.1-0
##                   mi         1.0
##                 mime         0.8
##               miniUI     0.1.1.1
##                minqa       1.2.4
##               mnormt       1.5-5
##               modelr       0.1.5
##           modeltools      0.2-22
##                 MOTE       1.0.2
##             multcomp      1.4-12
##         multcompView       0.1-8
##                MuMIn     1.43.15
##              munsell       0.5.0
##           mvnormtest       0.1-9
##              mvtnorm      1.0-12
##                nlmeU      0.70-3
##               nloptr       1.2.1
##              nortest       1.0-4
##             numDeriv  2016.8-1.1
##              officer       0.3.6
##            oompaBase       3.2.9
##               OpenMx      2.15.5
##              openssl       1.4.1
##             openxlsx       4.1.4
##                 osfr       0.2.4
##              packrat       0.5.0
##  pairwiseComparisons       0.1.3
##            paletteer       1.0.0
##                 palr       0.1.0
##                 pals         1.6
##               pander       0.6.3
##               papaja  0.1.0.9842
##           parameters       0.4.1
##            patchwork       1.0.0
##              pbapply       1.4-2
##             pbivnorm       0.6.0
##             pbkrtest       0.4-7
##          performance       0.4.3
##               pillar       1.4.3
##             pkgbuild       1.0.6
##            pkgconfig       2.0.3
##              pkgload       1.0.2
##                  PKI     0.1-5.1
##                plogr       0.2.0
##              plotrix       3.7-7
##              plumber       0.4.6
##                 plyr       1.8.5
##                PMCMR         4.3
##                  png       0.1-7
##             polyclip      1.10-0
##                ppcor         1.1
##               praise       1.0.0
##               prereg       0.4.0
##          prettyunits       1.1.0
##            prismatic       0.2.0
##             processx       3.4.1
##             progress       1.2.2
##             promises       1.1.0
##                proto       1.0.0
##                   ps       1.3.0
##                psych   1.9.12.31
##                purrr       0.3.3
##            QuantPsyc         1.5
##             quantreg        5.54
##               qvcalc       1.0.1
##              R.cache      0.14.0
##          R.methodsS3       1.7.1
##                 R.oo      1.23.0
##              R.utils       2.9.2
##                   R6       2.4.1
##           randomizeR       2.0.0
##             rappdirs       0.3.1
##               raster       3.0-7
##            rcmdcheck       1.3.3
##         RColorBrewer       1.1-2
##           rcompanion      2.3.21
##                 Rcpp       1.0.3
##        RcppArmadillo 0.9.800.3.0
##            RcppEigen   0.3.3.7.0
##                RCurl   1.95-4.12
##             readbulk       1.1.2
##                readr       1.3.1
##               readxl       1.3.1
##           RefManageR      1.2.12
##               relimp       1.0-5
##              rematch       1.0.1
##             rematch2       2.1.0
##              remotes       2.1.0
##                 repr       1.0.2
##               reprex       0.3.0
##              reshape       0.8.8
##             reshape2       1.4.3
##             revealjs         0.9
##                  rex       1.1.2
##          RgoogleMaps     1.4.5.1
##                  rio      0.5.16
##                rJava      0.9-11
##                rjson      0.2.20
##              RJSONIO     1.3-1.4
##                rlang       0.4.2
##               RLRsim       3.1-3
##            rmarkdown         2.1
##             rmdfiltr       0.1.2
##                 ROCR       1.0-7
##               rorcid       0.5.0
##             roxygen2       7.0.2
##           rpart.plot       3.0.8
##                  rpf        0.62
##            rprojroot       1.3-2
##          rqdatatable       1.2.5
##               rquery       1.4.2
##            rsconnect      0.8.16
##            RSelenium       1.7.5
##                rstan      2.19.2
##           rstantools       2.0.0
##           rstudioapi        0.10
##              rticles        0.13
##             Rttf2pt1       1.3.8
##            rversions       2.0.1
##                rvest       0.3.5
##             sandwich       2.5-1
##               scales       1.1.0
##              scholar       0.1.7
##                scico       1.1.0
##         scienceverse  0.0.0.9001
##              selectr       0.4-2
##                  sem       3.1-9
##             semTools       0.5-2
##               semver       0.2.0
##                servr        0.15
##          sessioninfo       1.1.1
##                shape       1.4.4
##                shiny       1.4.0
##       shinydashboard       0.7.1
##              shinyjs         1.1
##          shinythemes       1.1.2
##                 sigr       1.0.6
##                 simr       1.0.5
##           sjlabelled       1.1.2
##               sjmisc       2.8.3
##               sjPlot       2.8.1
##              sjstats      0.17.8
##                skimr       2.0.2
##                   sm     2.2-5.6
##            SnowballC       0.6.0
##          sourcetools       0.1.7
##                   sp       1.3-2
##              SparseM        1.78
##          StanHeaders    2.21.0-1
##     statsExpressions       0.2.0
##            stopwords         1.0
##              stringi       1.4.5
##              stringr       1.4.0
##           subprocess       0.8.3
##                sylly       0.1-5
##             sylly.en       0.1-3
##                  sys         3.3
##          systemfonts       0.1.1
##               tables       0.8.8
##             testthat       2.3.1
##              TH.data      1.0-10
##               tibble       2.1.3
##            tidygraph       1.1.2
##                tidyr       1.0.0
##           tidyselect       0.2.5
##             tidytext       0.2.2
##            tidyverse       1.3.0
##              tinytex        0.19
##                  TMB      1.7.16
##           tokenizers       0.2.1
##           translateR         2.0
##            triebeard       0.3.0
##            truncnorm       1.0-8
##               tweenr       1.0.1
##             urltools       1.7.3
##              usethis       1.5.1
##                 utf8       1.1.4
##                 uuid       0.1-2
##                  vcd       1.4-5
##             vcdExtra       0.7-1
##                vctrs       0.2.1
##              viridis       0.5.1
##          viridisLite       0.3.0
##                wdman       0.2.4
##              webshot       0.5.2
##          wesanderson       0.3.6
##              whisker         0.4
##                withr       2.1.2
##       wordcountaddin  0.3.0.9000
##            workflowr       1.6.0
##                wrapr       1.9.5
##                 WRS2       1.0-0
##              WVPlots       1.2.3
##              WWGbook       1.0.1
##             xaringan        0.14
##                 xfun        0.12
##            XLConnect      0.2-15
##        XLConnectJars      0.2-15
##                 xlsx       0.6.1
##             xlsxjars       0.6.1
##                  XML   3.98-1.20
##                 xml2       1.2.2
##                xopen       1.0.0
##               xtable       1.8-4
##                 yaml       2.2.0
##              zeallot       0.1.0
##                  zip       2.0.4
##                  zoo       1.8-7&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(paste0(&amp;quot;There are &amp;quot;,dim(ip)[1], &amp;quot; packages installed in my laptop.&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;There are 404 packages installed in my laptop.&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Richard’s book inspired me help people control their golems/ststistical models in the process of coding. In his book, literature and codes are separated. Readers who are not familiar with coding skill might hardly follow his literature. Literatural coding might be the best way to impliment the &lt;code&gt;Rethinking&lt;/code&gt;. I am going to accumulating the codes of Bayesian statistics and thake notes of his and others literatures in the coming posts.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Vectors in mathematics and in codes</title>
      <link>/post/2016-04-05-vectors-in-mathematics-and-in-codes/</link>
      <pubDate>Tue, 05 Apr 2016 00:00:00 +0000</pubDate>
      <guid>/post/2016-04-05-vectors-in-mathematics-and-in-codes/</guid>
      <description>


&lt;p&gt;When a set of data/observations is imported to R, it is usually treated as &lt;code&gt;vector&lt;/code&gt;. Vector has two mathematical forms as following:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;column vector&lt;/strong&gt;:&lt;br /&gt;
&lt;span class=&#34;math display&#34;&gt;\[ \vec{a} = \begin{bmatrix}
 1\\
 2\\
 3\\
\end{bmatrix} \]&lt;/span&gt;&lt;br /&gt;
&lt;strong&gt;row vector&lt;/strong&gt;:&lt;br /&gt;
&lt;span class=&#34;math display&#34;&gt;\[ \vec{a} = [ 1\ 2\ 3 ] \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Default form of vector in R is column vector. More precisely, it is treated as a matrix:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;a &amp;lt;- 1:3
a&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1 2 3&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;class(a)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;integer&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str(a)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  int [1:3] 1 2 3&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t(a)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1] [,2] [,3]
## [1,]    1    2    3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In a statistical work, we used to calcuate the sum of square (SS) for the deviations to mean. The common equation is like:&lt;br /&gt;
&lt;span class=&#34;math display&#34;&gt;\[ \sum_{i=1}^{n}(Y_{i}-\overline{Y})^2 \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This is the fundemental for calculating the variance of this set of data/observations. The equation of variance is like this:&lt;br /&gt;
&lt;span class=&#34;math display&#34;&gt;\[ \frac{\sum_{i=1}^{n}(Y_{i}-\overline{Y})^2}{n} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Because the data/observations are treated as matrix, we are able to have the sum of square by the multiplication of this matrix.&lt;br /&gt;
&lt;span class=&#34;math display&#34;&gt;\[ \mathbf{A&amp;#39;A} = 
\begin{bmatrix} A_1 A_2 A_3 \dots\end{bmatrix}
\times
\begin{bmatrix}
   A_1 \\
   A_2 \\
   A_3 \\
   \vdots
\end{bmatrix}　\]&lt;/span&gt;　　&lt;/p&gt;
&lt;p&gt;Here are ten observations 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, the average of this data is 5.5. Let’s have the SS and variance in use of the multiplication of matrix:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;SS &amp;lt;- t(1:10 - mean(1:10)) %*% (1:10 - mean(1:10)) 
VAR &amp;lt;- SS/length(1:10)
SS&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1]
## [1,] 82.5&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;VAR&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1]
## [1,] 8.25&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In R &lt;code&gt;base&lt;/code&gt; package, the function &lt;code&gt;var&lt;/code&gt; outputs a sampling variance, not a population variance as above.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;var(1:10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 9.166667&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Learning Sampling Distribution in R Programming</title>
      <link>/post/2016-03-30-learning-sampling-distribution-in-r-programming/</link>
      <pubDate>Wed, 30 Mar 2016 00:00:00 +0000</pubDate>
      <guid>/post/2016-03-30-learning-sampling-distribution-in-r-programming/</guid>
      <description>


&lt;p&gt;Sampling distribution is the set of possible outcomes when we collect data through the randomization procedure (random sampling, ramond assignment). Do a simulation work is the best way to understand the sampling distribution. A simulation work is unrelated to any context we collect the data. You can connect the simulation work to any randominzation in the real world.&lt;/p&gt;
&lt;p&gt;In this pseudo experiment, there are only ten observations we will collect in every sample. They are 1, 2, 3, 4, 5, 6, 7, 8, 9, 10. Accodring to the design of the experiment, a sample will have one observation to countless observations. I assume the distrubtions are accumulated from 100 samples of 1 observation, 9 observations, ,16 observations, 25 observations, and 36 observations. Every sample will be collapsed to a average value and become the components of sampling distribution. I use &lt;code&gt;ggplot2&lt;/code&gt; to draw the five sampling distributions. Look at what they are look like.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;suppressPackageStartupMessages({
  library(ggplot2)
  library(xtable)
  })

set.seed(1)
OBV &amp;lt;- 1:10
Dist1 &amp;lt;- NULL
Dist9 &amp;lt;- NULL
Dist16 &amp;lt;- NULL
Dist25 &amp;lt;- NULL
Dist36 &amp;lt;- NULL
count = 100
while(count &amp;gt; 0){Dist1 &amp;lt;- c(Dist1,sample(OBV, 1, replace = TRUE)); count &amp;lt;- count - 1}
count = 100
while(count &amp;gt; 0){Dist9 &amp;lt;- c(Dist9,mean(sample(OBV, 9,replace = TRUE) ) ); count &amp;lt;- count - 1}
count = 100
while(count &amp;gt; 0){Dist16 &amp;lt;- c(Dist16,mean(sample(OBV, 16,replace = TRUE) ) ); count &amp;lt;- count - 1}
count = 100
while(count &amp;gt; 0){Dist25 &amp;lt;- c(Dist25,mean(sample(OBV, 25,replace = TRUE) ) ); count &amp;lt;- count - 1}
count = 100
while(count &amp;gt; 0){Dist36 &amp;lt;- c(Dist36,mean(sample(OBV, 36,replace = TRUE) ) ); count &amp;lt;- count - 1}
Dist.df &amp;lt;- data.frame(Size = factor(rep(c(1,9,16,25,36), each=100)), Sample_Means = c(Dist1, Dist9, Dist16, Dist25, Dist36) )
ggplot(Dist.df, aes(Sample_Means, fill = Size)) + geom_histogram() + facet_grid(. ~ Size)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/en/post/2016-03-30-learning-sampling-distribution-in-r-programming_files/figure-html/Sampling-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We call the set of observations 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 &lt;strong&gt;population&lt;/strong&gt; in any circumstance we conduct this experiment. This population has the average 5.5 and the variance/standard deviation 8.25/2.87. With the increase of sample size, you find more and more samples collapsed to the average of population. The variation of each sample distribution decreases with the increasing of sample size as well. The following table illustrate the average and variance/standard deviation of each sampling distribution.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;Sample Size&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Average&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Variance&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Standard Deviation&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;6.06&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;8.14&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.85&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5.62&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.91&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.96&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;16&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5.6&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.58&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.76&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;25&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5.54&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.43&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.66&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;36&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5.51&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.27&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.52&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;There are three findings in this simulation. First, the average of every sample is as equal as the average of population. Second, the variance of every sample is close to the divide of population variance by the sample size. Third, the standard deviation of every sample is close to the divide of population standard deviation by the square of sample size. These facts matches &lt;a href=&#34;https://en.wikipedia.org/wiki/Central_limit_theorem&#34;&gt;Central limit theorem&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
